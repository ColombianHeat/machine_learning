{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee28e49a-7b53-497d-9faa-5e22bcee0756",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-21T01:19:45.096276Z",
     "iopub.status.busy": "2023-01-21T01:19:45.095593Z",
     "iopub.status.idle": "2023-01-21T01:19:45.101408Z",
     "shell.execute_reply": "2023-01-21T01:19:45.100567Z",
     "shell.execute_reply.started": "2023-01-21T01:19:45.096200Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Current 22-Jan-2023\n",
    "\n",
    "My first proper machine learning project!\n",
    "\n",
    "Takes as input a list of room names and floor areas. Outputs one of 76 ASHRAE space usage categories per room. Useful in automating\n",
    " a crucial step when calculating the loads of a building.\n",
    "\n",
    " Some tuning of the hyperparameters is still required; the model successfully makes predictions, but they are not great predictions.\n",
    " Having more than 700 data points for training and validation would also likely help.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadee706-737c-4817-9b32-a8ce70b9db81",
   "metadata": {},
   "source": [
    "### Dataframe Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4099cb0-6d60-4480-bbd9-c6fb4a660717",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-21T01:19:45.103269Z",
     "iopub.status.busy": "2023-01-21T01:19:45.102947Z",
     "iopub.status.idle": "2023-01-21T01:19:45.118237Z",
     "shell.execute_reply": "2023-01-21T01:19:45.117227Z",
     "shell.execute_reply.started": "2023-01-21T01:19:45.103238Z"
    }
   },
   "outputs": [],
   "source": [
    "space_usage_cats = ['User-Defined',\n",
    "                    'CORRECTIONAL FACILITY: Booking/waiting',\n",
    "                    'CORRECTIONAL FACILITY: Cell',\n",
    "                    'CORRECTIONAL FACILITY: Dayroom',\n",
    "                    'CORRECTIONAL FACILITY: Guard stations',\n",
    "                    'EDUCATION: Art classroom',\n",
    "                    'EDUCATION: Classroom (age 9 plus)',\n",
    "                    'EDUCATION: Classroom (ages 5-8)',\n",
    "                    'EDUCATION: Computer Lab',\n",
    "                    'EDUCATION: Daycare (through age 4)',\n",
    "                    'EDUCATION: Daycare Sickroom',\n",
    "                    'EDUCATION: Lecture Classroom',\n",
    "                    'EDUCATION: Lecture Hall (fixed seats)',\n",
    "                    'EDUCATION: Media Center',\n",
    "                    'EDUCATION: Multiuse Assembly',\n",
    "                    'EDUCATION: Music/theater/dance',\n",
    "                    'EDUCATION: Science Laboratory',\n",
    "                    'EDUCATION: University/college Laboratory',\n",
    "                    'EDUCATION: Wood/metal Shop',\n",
    "                    'FOOD AND BEVERAGE SERVICE: Bar, Cocktail Lounge',\n",
    "                    'FOOD AND BEVERAGE SERVICE: Cafeteria/Fast Food Dining',\n",
    "                    'FOOD AND BEVERAGE SERVICE: Kitchen (cooking)',\n",
    "                    'FOOD AND BEVERAGE SERVICE: Restaurant Dining Room',\n",
    "                    'GENERAL: Break Room',\n",
    "                    'GENERAL: Coffee Station',\n",
    "                    'GENERAL: Conference/Meeting',\n",
    "                    'GENERAL: Corridor',\n",
    "                    'GENERAL: Occupiable Storage Room (liq/gel)',\n",
    "                    'HOTEL / MOTEL / RESORT / DORM: Barracks sleeping area',\n",
    "                    'HOTEL / MOTEL / RESORT / DORM: Bedroom/Living Room',\n",
    "                    'HOTEL / MOTEL / RESORT / DORM: Laundry Room Within Dwelling Unit', # confirm if correct\n",
    "                    'HOTEL / MOTEL / RESORT / DORM: Laundry Room, Central',\n",
    "                    'HOTEL / MOTEL / RESORT / DORM: Lobby/Prefunction',\n",
    "                    'HOTEL / MOTEL / RESORT / DORM: Multipurpose Assembly',\n",
    "                    'MISCELLANEOUS: Bank or Bank Lobby',\n",
    "                    'MISCELLANEOUS: Bank Vault/Safe Deposit',\n",
    "                    'MISCELLANEOUS: Computer (not printing)',\n",
    "                    'MISCELLANEOUS: Freezer and Refrigerated Spaces (<50Â°F)',\n",
    "                    'MISCELLANEOUS: General Manufacturing (EXCLUDES HEAVY INDUSTRIAL AND PROCESSES USING CHEMICALS)',\n",
    "                    'MISCELLANEOUS: Pharmacy (prep. area)',\n",
    "                    'MISCELLANEOUS: Photo Studio',\n",
    "                    'MISCELLANEOUS: Shipping/Receiving',\n",
    "                    'MISCELLANEOUS: Sorting, Packing, Light Assembly',\n",
    "                    'MISCELLANEOUS: Telephone Closet',\n",
    "                    'MISCELLANEOUS: Transportation Waiting',\n",
    "                    'MISCELLANEOUS: Warehouse',\n",
    "                    'OFFICE: Breakroom',\n",
    "                    'OFFICE: Main Entry Lobby',\n",
    "                    'OFFICE: Occupiable Storage Room for Dry Materials',\n",
    "                    'OFFICE: Office Space',\n",
    "                    'OFFICE: Reception Area',\n",
    "                    'OFFICE: Telephone/Data Entry',\n",
    "                    'PUBLIC ASSEMBLY: Auditorium Seating Area',\n",
    "                    'PUBLIC ASSEMBLY: Courtroom',\n",
    "                    'PUBLIC ASSEMBLY: Legislative Chamber',\n",
    "                    'PUBLIC ASSEMBLY: Library',\n",
    "                    'PUBLIC ASSEMBLY: Lobby',\n",
    "                    'PUBLIC ASSEMBLY: Museum (Children\\'s)',\n",
    "                    'PUBLIC ASSEMBLY: Museum/Gallery',\n",
    "                    'PUBLIC ASSEMBLY: Place of Religious Worship',\n",
    "                    'RESIDENTIAL: Common Corridor',\n",
    "                    'RESIDENTIAL: Dwelling Unit',\n",
    "                    'RETAIL: Barbershop',\n",
    "                    'RETAIL: Beauty and Nail Salon',\n",
    "                    'RETAIL: Coin-operated laundry',\n",
    "                    'RETAIL: Mall common area',\n",
    "                    'RETAIL: Pet shop (animal area)',\n",
    "                    'RETAIL: Sales (except other categories here)',\n",
    "                    'RETAIL: Supermarket',\n",
    "                    'SPORTS: Bowling alley (seating)',\n",
    "                    'SPORTS: Disco/dance floor',\n",
    "                    'SPORTS: Gambling casino',\n",
    "                    'SPORTS: Game arcade',\n",
    "                    'SPORTS: Gym, sports arena (play area)',\n",
    "                    'SPORTS: Health club/aerobics room',\n",
    "                    'SPORTS: Health club/weight room',\n",
    "                    'SPORTS: Spectator area',\n",
    "                    'SPORTS: Stage, studio',\n",
    "                    'SPORTS: Swimming (pool & deck)'\n",
    "                    ]\n",
    "\n",
    "SPACE_USAGE_CATS = []\n",
    "for category in space_usage_cats:\n",
    "    SPACE_USAGE_CATS.append(category.upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2dcc1a03-f951-44e8-b81e-0dfe276d15fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-21T01:19:45.119930Z",
     "iopub.status.busy": "2023-01-21T01:19:45.119350Z",
     "iopub.status.idle": "2023-01-21T01:19:45.526119Z",
     "shell.execute_reply": "2023-01-21T01:19:45.524880Z",
     "shell.execute_reply.started": "2023-01-21T01:19:45.119927Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>area</th>\n",
       "      <th>usage_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [name, area, usage_cat]\n",
       "Index: []"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_pickle('combined_df.pickle')\n",
    "df.usage_cat = df.usage_cat.str.upper()\n",
    "df.name = df.name.str.upper()\n",
    "df.loc[df.usage_cat == 'EDUCATION: CLASSROOM (AGE 9+)', 'usage_cat'] = 'EDUCATION: CLASSROOM (AGE 9 PLUS)'\n",
    "df.loc[df.usage_cat == 'FOOD SERVICE: CAFETERIA/FAST FOOD', 'usage_cat'] = 'FOOD AND BEVERAGE SERVICE: CAFETERIA/FAST FOOD DINING'\n",
    "df.loc[df.usage_cat == 'FOOD SERVICE: KITCHEN (COOKING)', 'usage_cat'] = 'FOOD AND BEVERAGE SERVICE: KITCHEN (COOKING)'\n",
    "df.loc[df.usage_cat == 'FOOD SERVICE: RESTAURANT DINING ROOM', 'usage_cat'] = 'FOOD AND BEVERAGE SERVICE: RESTAURANT DINING ROOM'\n",
    "df.loc[df.usage_cat == 'EDUCATION: MULTI-USE ASSEMBLY', 'usage_cat'] = 'EDUCATION: MULTIUSE ASSEMBLY'\n",
    "df.loc[df.usage_cat == 'PUBLIC ASSEMBLY: AUDITORIUM', 'usage_cat'] = 'PUBLIC ASSEMBLY: AUDITORIUM SEATING AREA'\n",
    "df.loc[df.usage_cat == 'OFFICE: OCCUPIABLE STORAGE ROOM (DRY)', 'usage_cat'] = 'OFFICE: OCCUPIABLE STORAGE ROOM FOR DRY MATERIALS'\n",
    "df.loc[df.usage_cat == 'MISCELLANEOUS: GENERAL MANUFACTURING', 'usage_cat'] = 'MISCELLANEOUS: GENERAL MANUFACTURING (EXCLUDES HEAVY INDUSTRIAL AND PROCESSES USING CHEMICALS)'\n",
    "\n",
    "\n",
    "df[df.usage_cat.isin(['PUBLIC ASSEMBLY: AUDITORIUM'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fee3076e-7012-4a57-b2f4-f3af5031d380",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-21T01:19:45.528807Z",
     "iopub.status.busy": "2023-01-21T01:19:45.528490Z",
     "iopub.status.idle": "2023-01-21T01:19:45.538398Z",
     "shell.execute_reply": "2023-01-21T01:19:45.537708Z",
     "shell.execute_reply.started": "2023-01-21T01:19:45.528773Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>area</th>\n",
       "      <th>usage_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [name, area, usage_cat]\n",
       "Index: []"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# Checking to see if each value in the usage_cat column appears letter for letter in the full list of categories\n",
    "df[df.usage_cat.isin(SPACE_USAGE_CATS) == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3545c1e5-1a8d-4cdf-983b-dcec3787d9a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-21T01:19:45.539189Z",
     "iopub.status.busy": "2023-01-21T01:19:45.539052Z",
     "iopub.status.idle": "2023-01-21T01:19:45.546025Z",
     "shell.execute_reply": "2023-01-21T01:19:45.545050Z",
     "shell.execute_reply.started": "2023-01-21T01:19:45.539151Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42, 37, 79)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lists any categories which appear in our training data\n",
    "data_cats = df.usage_cat.tolist()\n",
    "present_cats = list(set(data_cats))\n",
    "present_cats.sort()\n",
    "\n",
    "# Lists any categories in the full list which do not appear in our training data\n",
    "missing_cats = list(set(SPACE_USAGE_CATS) - set(present_cats))\n",
    "missing_cats.sort()\n",
    "\n",
    "len(present_cats), len(missing_cats), len(SPACE_USAGE_CATS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9dfdcdc9-4446-45cc-a31f-fafefcbf8c16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-21T01:19:45.547736Z",
     "iopub.status.busy": "2023-01-21T01:19:45.547475Z",
     "iopub.status.idle": "2023-01-21T01:19:45.564691Z",
     "shell.execute_reply": "2023-01-21T01:19:45.563652Z",
     "shell.execute_reply.started": "2023-01-21T01:19:45.547711Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>area</th>\n",
       "      <th>usage_cat</th>\n",
       "      <th>usage_cat_integer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000 BASEMENT</td>\n",
       "      <td>1550</td>\n",
       "      <td>USER-DEFINED</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100 MAIN FLOOR</td>\n",
       "      <td>1120</td>\n",
       "      <td>OFFICE: OFFICE SPACE</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101 INTERVIEW/OW TRUSTEE</td>\n",
       "      <td>105</td>\n",
       "      <td>OFFICE: OFFICE SPACE</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201 APARTMENT</td>\n",
       "      <td>323</td>\n",
       "      <td>RESIDENTIAL: DWELLING UNIT</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201C BEDROOM</td>\n",
       "      <td>100</td>\n",
       "      <td>RESIDENTIAL: DWELLING UNIT</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>CR-03 CORRIDOR</td>\n",
       "      <td>1000</td>\n",
       "      <td>GENERAL: CORRIDOR</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>CR-05 CORRIDOR</td>\n",
       "      <td>950</td>\n",
       "      <td>GENERAL: CORRIDOR</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>V-01 VESTIBULE</td>\n",
       "      <td>50</td>\n",
       "      <td>USER-DEFINED</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>V-03 VESTIBULE</td>\n",
       "      <td>50</td>\n",
       "      <td>USER-DEFINED</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>V-04 VESTIBULE</td>\n",
       "      <td>60</td>\n",
       "      <td>USER-DEFINED</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>738 rows Ã 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        name  area                   usage_cat  \\\n",
       "0               000 BASEMENT  1550                USER-DEFINED   \n",
       "1             100 MAIN FLOOR  1120        OFFICE: OFFICE SPACE   \n",
       "2   101 INTERVIEW/OW TRUSTEE   105        OFFICE: OFFICE SPACE   \n",
       "3              201 APARTMENT   323  RESIDENTIAL: DWELLING UNIT   \n",
       "4               201C BEDROOM   100  RESIDENTIAL: DWELLING UNIT   \n",
       "..                       ...   ...                         ...   \n",
       "62            CR-03 CORRIDOR  1000           GENERAL: CORRIDOR   \n",
       "63            CR-05 CORRIDOR   950           GENERAL: CORRIDOR   \n",
       "64            V-01 VESTIBULE    50                USER-DEFINED   \n",
       "65            V-03 VESTIBULE    50                USER-DEFINED   \n",
       "66            V-04 VESTIBULE    60                USER-DEFINED   \n",
       "\n",
       "    usage_cat_integer  \n",
       "0                 0.0  \n",
       "1                49.0  \n",
       "2                49.0  \n",
       "3                61.0  \n",
       "4                61.0  \n",
       "..                ...  \n",
       "62               26.0  \n",
       "63               26.0  \n",
       "64                0.0  \n",
       "65                0.0  \n",
       "66                0.0  \n",
       "\n",
       "[738 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a column in the dataframe containing an integer corresponding to a category\n",
    "label_dict = dict(zip(SPACE_USAGE_CATS, range(len(SPACE_USAGE_CATS))))\n",
    "df['usage_cat_integer'] = df.usage_cat.map(label_dict)\n",
    "df.usage_cat_integer = df.usage_cat_integer.astype(float)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e2a9c53-958b-4672-acb8-fe23d39245e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-21T01:19:45.566046Z",
     "iopub.status.busy": "2023-01-21T01:19:45.565767Z",
     "iopub.status.idle": "2023-01-21T01:19:45.581907Z",
     "shell.execute_reply": "2023-01-21T01:19:45.580914Z",
     "shell.execute_reply.started": "2023-01-21T01:19:45.566020Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>area</th>\n",
       "      <th>usage_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>738</td>\n",
       "      <td>738</td>\n",
       "      <td>738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>737</td>\n",
       "      <td>412</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>ELECTRICAL ROOM</td>\n",
       "      <td>100</td>\n",
       "      <td>USER-DEFINED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>269</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   name area     usage_cat\n",
       "count               738  738           738\n",
       "unique              737  412            42\n",
       "top     ELECTRICAL ROOM  100  USER-DEFINED\n",
       "freq                  2   28           269"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8cfb44a0-4d7a-4bd0-9482-17a6b0ed9282",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-21T01:19:45.583601Z",
     "iopub.status.busy": "2023-01-21T01:19:45.583207Z",
     "iopub.status.idle": "2023-01-21T01:19:45.590291Z",
     "shell.execute_reply": "2023-01-21T01:19:45.589304Z",
     "shell.execute_reply.started": "2023-01-21T01:19:45.583567Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating our input column\n",
    "df['input'] = 'TEXT1: ' + df.name + '; TEXT2: ' + df.area"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e12309-d302-4f7c-bbe5-178dddf3e620",
   "metadata": {},
   "source": [
    "### Transformers Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca468664-6dc6-4da5-a223-3914119f47c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-21T01:19:45.593888Z",
     "iopub.status.busy": "2023-01-21T01:19:45.593562Z",
     "iopub.status.idle": "2023-01-21T01:19:45.991257Z",
     "shell.execute_reply": "2023-01-21T01:19:45.990706Z",
     "shell.execute_reply.started": "2023-01-21T01:19:45.593861Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['name', 'area', 'usage_cat', 'usage_cat_integer', 'input', '__index_level_0__'],\n",
       "    num_rows: 738\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a dataset for Transformers to use\n",
    "from datasets import Dataset,DatasetDict\n",
    "\n",
    "ds = Dataset.from_pandas(df)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af27712a-624a-46dd-857c-0da45253229d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-21T01:19:45.993151Z",
     "iopub.status.busy": "2023-01-21T01:19:45.992694Z",
     "iopub.status.idle": "2023-01-21T01:19:46.758976Z",
     "shell.execute_reply": "2023-01-21T01:19:46.758187Z",
     "shell.execute_reply.started": "2023-01-21T01:19:45.993151Z"
    }
   },
   "outputs": [],
   "source": [
    "# Select a pre-trained model and use it to create a tokenizer\n",
    "model_nm = 'bert-base-uncased'\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "tokenize = AutoTokenizer.from_pretrained(model_nm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83805188-cd2d-4cdc-8b54-316c9530894d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-21T01:19:46.760405Z",
     "iopub.status.busy": "2023-01-21T01:19:46.760154Z",
     "iopub.status.idle": "2023-01-21T01:19:46.766622Z",
     "shell.execute_reply": "2023-01-21T01:19:46.765950Z",
     "shell.execute_reply.started": "2023-01-21T01:19:46.760365Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this',\n",
       " 'is',\n",
       " 'an',\n",
       " 'absolutely',\n",
       " 'amazing',\n",
       " 'sentence',\n",
       " 'which',\n",
       " 'is',\n",
       " 'getting',\n",
       " 'token',\n",
       " '##ized',\n",
       " 'right',\n",
       " 'now',\n",
       " '!',\n",
       " '!',\n",
       " '!']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize.tokenize('This is an absolutely amazing sentence which is getting tokenized right now!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a7a7517-4182-42b6-9325-b9eec89877e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-21T01:19:46.767707Z",
     "iopub.status.busy": "2023-01-21T01:19:46.767472Z",
     "iopub.status.idle": "2023-01-21T01:19:46.771296Z",
     "shell.execute_reply": "2023-01-21T01:19:46.770558Z",
     "shell.execute_reply.started": "2023-01-21T01:19:46.767684Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to tokenize the 'input' column of our dataframe\n",
    "def tokenize_fnc(x):\n",
    "    return tokenize(x['input'], truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b87ff04-d1c6-45e1-9d94-d5cf7e1861b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-21T01:19:46.772487Z",
     "iopub.status.busy": "2023-01-21T01:19:46.772258Z",
     "iopub.status.idle": "2023-01-21T01:19:47.039661Z",
     "shell.execute_reply": "2023-01-21T01:19:47.038465Z",
     "shell.execute_reply.started": "2023-01-21T01:19:46.772466Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function tokenize_fnc at 0x7f9329ea3820> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bef40b237cdb4fb88a19b643384392c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/738 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tokenize our dataset!\n",
    "tokenized_ds = ds.map(tokenize_fnc, batched=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa516fc6-7a9a-4547-8fff-570df83e88c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-21T01:19:47.041145Z",
     "iopub.status.busy": "2023-01-21T01:19:47.040865Z",
     "iopub.status.idle": "2023-01-21T01:19:47.048222Z",
     "shell.execute_reply": "2023-01-21T01:19:47.047398Z",
     "shell.execute_reply.started": "2023-01-21T01:19:47.041113Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': '000 BASEMENT',\n",
       " 'area': '1550',\n",
       " 'usage_cat': 'USER-DEFINED',\n",
       " 'usage_cat_integer': 0.0,\n",
       " 'input': 'TEXT1: 000 BASEMENT; TEXT2: 1550',\n",
       " '__index_level_0__': 0,\n",
       " 'input_ids': [101,\n",
       "  3793,\n",
       "  2487,\n",
       "  1024,\n",
       "  2199,\n",
       "  8102,\n",
       "  1025,\n",
       "  3793,\n",
       "  2475,\n",
       "  1024,\n",
       "  26245,\n",
       "  102],\n",
       " 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58c86e28-8928-45ea-8caa-e4d73d996496",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-21T01:19:47.049375Z",
     "iopub.status.busy": "2023-01-21T01:19:47.049142Z",
     "iopub.status.idle": "2023-01-21T01:19:47.810300Z",
     "shell.execute_reply": "2023-01-21T01:19:47.809373Z",
     "shell.execute_reply.started": "2023-01-21T01:19:47.049362Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['labels', '__index_level_0__', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 738\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transformers assumes that our labels column is always named 'labels'\n",
    "tokenized_ds = tokenized_ds.rename_columns({'usage_cat_integer': 'labels'})\n",
    "tokenized_ds = tokenized_ds.remove_columns(['input', 'name', 'area', 'usage_cat'])\n",
    "\n",
    "columns_to_return = ['input_ids', 'labels', 'attention_mask', 'token_type_ids']\n",
    "tokenized_ds.set_format(type='torch', columns=columns_to_return)\n",
    "tokenized_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "86077e80-2fae-446d-8347-889062488e54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-21T01:19:47.812208Z",
     "iopub.status.busy": "2023-01-21T01:19:47.811561Z",
     "iopub.status.idle": "2023-01-21T01:19:47.818245Z",
     "shell.execute_reply": "2023-01-21T01:19:47.817528Z",
     "shell.execute_reply.started": "2023-01-21T01:19:47.812208Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_ds.format['type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "74ff444b-e176-4c9a-801e-e8e97ad569e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-21T01:19:47.819517Z",
     "iopub.status.busy": "2023-01-21T01:19:47.819038Z",
     "iopub.status.idle": "2023-01-21T01:19:47.832373Z",
     "shell.execute_reply": "2023-01-21T01:19:47.831425Z",
     "shell.execute_reply.started": "2023-01-21T01:19:47.819517Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['labels', '__index_level_0__', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 553\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['labels', '__index_level_0__', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 185\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split into training and validation sets. 75% of data will be training data and\n",
    "# 25% will be validation data\n",
    "dds = tokenized_ds.train_test_split(0.25)\n",
    "dds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5af77000-483a-4283-a424-e315aad2e40d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-21T01:19:47.833575Z",
     "iopub.status.busy": "2023-01-21T01:19:47.833262Z",
     "iopub.status.idle": "2023-01-21T01:19:54.317132Z",
     "shell.execute_reply": "2023-01-21T01:19:54.316134Z",
     "shell.execute_reply.started": "2023-01-21T01:19:47.833543Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: evaluate in /usr/local/lib/python3.9/dist-packages (0.4.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from evaluate) (21.3)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.9/dist-packages (from evaluate) (2022.5.0)\n",
      "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.9/dist-packages (from evaluate) (0.18.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from evaluate) (1.4.3)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.9/dist-packages (from evaluate) (3.0.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from evaluate) (2.28.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from evaluate) (1.23.1)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.9/dist-packages (from evaluate) (4.64.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from evaluate) (0.8.1)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from evaluate) (2.3.2)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.9/dist-packages (from evaluate) (0.70.13)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.9/dist-packages (from evaluate) (0.3.5.1)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.9/dist-packages (from datasets>=2.0.0->evaluate) (3.8.1)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.9/dist-packages (from datasets>=2.0.0->evaluate) (8.0.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.7.0->evaluate) (5.4.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.7.0->evaluate) (3.7.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from packaging->evaluate) (3.0.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.19.0->evaluate) (2.8)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->evaluate) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.19.0->evaluate) (2019.11.28)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->evaluate) (1.26.10)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->evaluate) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.14.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (18.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.7.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install evaluate\n",
    "import evaluate\n",
    "\n",
    "metric = evaluate.load('accuracy')\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455af53b-eac6-4f66-b375-44f3d12b0916",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c6eb008b-18a6-4c1c-b09a-de1b29da509b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-21T01:19:54.319359Z",
     "iopub.status.busy": "2023-01-21T01:19:54.318680Z",
     "iopub.status.idle": "2023-01-21T01:19:54.347785Z",
     "shell.execute_reply": "2023-01-21T01:19:54.346908Z",
     "shell.execute_reply.started": "2023-01-21T01:19:54.319321Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer, DataCollatorWithPadding\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 4\n",
    "epochs = 8\n",
    "learn_rate = 5e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4f7023f1-82f6-4c64-a94e-05891e990f10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-21T01:19:54.349524Z",
     "iopub.status.busy": "2023-01-21T01:19:54.349156Z",
     "iopub.status.idle": "2023-01-21T01:19:54.357126Z",
     "shell.execute_reply": "2023-01-21T01:19:54.356280Z",
     "shell.execute_reply.started": "2023-01-21T01:19:54.349489Z"
    }
   },
   "outputs": [],
   "source": [
    "args = TrainingArguments('outputs', learning_rate=learn_rate, warmup_ratio=0.1, lr_scheduler_type='cosine', fp16=True,\n",
    "    evaluation_strategy=\"epoch\", per_device_train_batch_size=batch_size, per_device_eval_batch_size=batch_size*2,\n",
    "    num_train_epochs=epochs, weight_decay=0.01, report_to='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8865297a-c90b-48f7-9e0c-70ce8d4ae442",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-21T01:19:54.358396Z",
     "iopub.status.busy": "2023-01-21T01:19:54.358149Z",
     "iopub.status.idle": "2023-01-21T01:19:58.829756Z",
     "shell.execute_reply": "2023-01-21T01:19:58.828755Z",
     "shell.execute_reply.started": "2023-01-21T01:19:54.358365Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using cuda_amp half precision backend\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(model_nm, num_labels=1)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenize)\n",
    "\n",
    "trainer = Trainer(model, args, train_dataset=dds['train'], eval_dataset=dds['test'], data_collator=data_collator,\n",
    "                  tokenizer=tokenize, compute_metrics=compute_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e4f8f4d0-7e51-43f9-a880-447903daad63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-21T01:19:58.831509Z",
     "iopub.status.busy": "2023-01-21T01:19:58.831499Z",
     "iopub.status.idle": "2023-01-21T01:19:58.841719Z",
     "shell.execute_reply": "2023-01-21T01:19:58.840757Z",
     "shell.execute_reply.started": "2023-01-21T01:19:58.831509Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__. If __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataCollatorWithPadding(tokenizer=PreTrainedTokenizerFast(name_or_path='bert-base-uncased', vocab_size=30522, model_max_len=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}), padding=True, max_length=None, pad_to_multiple_of=None, return_tensors='pt')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_collator = trainer.get_train_dataloader().collate_fn\n",
    "data_collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "85c3f523-0dd0-42c8-9b94-00a374ddac22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-21T01:19:58.843696Z",
     "iopub.status.busy": "2023-01-21T01:19:58.843364Z",
     "iopub.status.idle": "2023-01-21T01:23:43.786097Z",
     "shell.execute_reply": "2023-01-21T01:23:43.785111Z",
     "shell.execute_reply.started": "2023-01-21T01:19:58.843670Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__. If __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/usr/local/lib/python3.9/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 553\n",
      "  Num Epochs = 8\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1112\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1112' max='1112' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1112/1112 03:44, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>463.718842</td>\n",
       "      <td>0.324324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>406.585968</td>\n",
       "      <td>0.324324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>396.069977</td>\n",
       "      <td>0.324324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>455.493500</td>\n",
       "      <td>358.036743</td>\n",
       "      <td>0.324324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>455.493500</td>\n",
       "      <td>388.309875</td>\n",
       "      <td>0.324324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>455.493500</td>\n",
       "      <td>364.519012</td>\n",
       "      <td>0.324324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>455.493500</td>\n",
       "      <td>360.052948</td>\n",
       "      <td>0.324324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>279.248300</td>\n",
       "      <td>364.001099</td>\n",
       "      <td>0.324324</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__. If __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 185\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__. If __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 185\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__. If __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 185\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to outputs/checkpoint-500\n",
      "Configuration saved in outputs/checkpoint-500/config.json\n",
      "Model weights saved in outputs/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in outputs/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in outputs/checkpoint-500/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__. If __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 185\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__. If __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 185\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__. If __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 185\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__. If __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 185\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to outputs/checkpoint-1000\n",
      "Configuration saved in outputs/checkpoint-1000/config.json\n",
      "Model weights saved in outputs/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in outputs/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in outputs/checkpoint-1000/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__. If __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 185\n",
      "  Batch size = 8\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1112, training_loss=356.21151711443343, metrics={'train_runtime': 224.6861, 'train_samples_per_second': 19.69, 'train_steps_per_second': 4.949, 'total_flos': 39239681031594.0, 'train_loss': 356.21151711443343, 'epoch': 8.0})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "trainer.train()\n",
    "# trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994b5e32-229a-43da-92a1-f3f1d8bf3c9e",
   "metadata": {},
   "source": [
    "### Testing Outputs of our Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2a47c861-b480-49bd-b0ba-c456e336ff47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-21T01:23:43.791277Z",
     "iopub.status.busy": "2023-01-21T01:23:43.790705Z",
     "iopub.status.idle": "2023-01-21T01:23:43.796453Z",
     "shell.execute_reply": "2023-01-21T01:23:43.795491Z",
     "shell.execute_reply.started": "2023-01-21T01:23:43.791277Z"
    }
   },
   "outputs": [],
   "source": [
    "# Figure out a way to save the model for later use on local computer. torch.save doesn't work??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ea79b2f2-b86f-4570-ae5e-f1f1be98d2ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-21T01:23:43.800219Z",
     "iopub.status.busy": "2023-01-21T01:23:43.799984Z",
     "iopub.status.idle": "2023-01-21T01:23:43.815089Z",
     "shell.execute_reply": "2023-01-21T01:23:43.813735Z",
     "shell.execute_reply.started": "2023-01-21T01:23:43.800194Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>area</th>\n",
       "      <th>input</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LOBBY</td>\n",
       "      <td>300</td>\n",
       "      <td>TEXT1: LOBBY; TEXT2: 300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>STAFF OFFICE</td>\n",
       "      <td>220</td>\n",
       "      <td>TEXT1: STAFF OFFICE; TEXT2: 220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VESTIBULE</td>\n",
       "      <td>100</td>\n",
       "      <td>TEXT1: VESTIBULE; TEXT2: 100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           name area                            input\n",
       "0         LOBBY  300         TEXT1: LOBBY; TEXT2: 300\n",
       "1  STAFF OFFICE  220  TEXT1: STAFF OFFICE; TEXT2: 220\n",
       "2     VESTIBULE  100     TEXT1: VESTIBULE; TEXT2: 100"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepping a dataframe with sample inputs\n",
    "room_info = [['Lobby', 300], ['Staff Office', 220], ['Vestibule', 100]]\n",
    "\n",
    "pred_df = pd.DataFrame(room_info, columns=['name', 'area'])\n",
    "pred_df.name = pred_df.name.str.upper()\n",
    "pred_df.area = pred_df.area.astype(str)\n",
    "pred_df['input'] = 'TEXT1: ' + pred_df.name + '; TEXT2: ' + pred_df.area\n",
    "pred_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e8f5dbef-155a-4cd8-abf5-418bc6874b30",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-21T01:23:43.818614Z",
     "iopub.status.busy": "2023-01-21T01:23:43.818390Z",
     "iopub.status.idle": "2023-01-21T01:23:43.862968Z",
     "shell.execute_reply": "2023-01-21T01:23:43.862037Z",
     "shell.execute_reply.started": "2023-01-21T01:23:43.818591Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f16efd6b779448c6b245c01f6089044f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 3\n",
       "})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting our dataframe to a dataset\n",
    "pred_ds = Dataset.from_pandas(pred_df).map(tokenize_fnc, batched=False)\n",
    "\n",
    "pred_ds = pred_ds.remove_columns(['input', 'name', 'area'])\n",
    "columns_to_return = ['input_ids', 'attention_mask', 'token_type_ids']\n",
    "pred_ds.set_format(type='torch', columns=columns_to_return)\n",
    "\n",
    "pred_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8c42236e-dbd9-409a-92f4-951899d386e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-21T01:23:43.866527Z",
     "iopub.status.busy": "2023-01-21T01:23:43.866309Z",
     "iopub.status.idle": "2023-01-21T01:23:43.942402Z",
     "shell.execute_reply": "2023-01-21T01:23:43.941257Z",
     "shell.execute_reply.started": "2023-01-21T01:23:43.866504Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 3\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(3,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Running our inputs in dataset form through the model\n",
    "preds = trainer.predict(pred_ds).predictions.astype(int)\n",
    "preds = np.squeeze(preds)\n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f034dfc3-3dd4-49c7-a03a-3acd7a6100c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-21T01:23:43.946346Z",
     "iopub.status.busy": "2023-01-21T01:23:43.946116Z",
     "iopub.status.idle": "2023-01-21T01:23:43.957819Z",
     "shell.execute_reply": "2023-01-21T01:23:43.956888Z",
     "shell.execute_reply.started": "2023-01-21T01:23:43.946323Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>area</th>\n",
       "      <th>input</th>\n",
       "      <th>cat_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LOBBY</td>\n",
       "      <td>300</td>\n",
       "      <td>TEXT1: LOBBY; TEXT2: 300</td>\n",
       "      <td>FOOD AND BEVERAGE SERVICE: BAR, COCKTAIL LOUNGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>STAFF OFFICE</td>\n",
       "      <td>220</td>\n",
       "      <td>TEXT1: STAFF OFFICE; TEXT2: 220</td>\n",
       "      <td>FOOD AND BEVERAGE SERVICE: BAR, COCKTAIL LOUNGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VESTIBULE</td>\n",
       "      <td>100</td>\n",
       "      <td>TEXT1: VESTIBULE; TEXT2: 100</td>\n",
       "      <td>USER-DEFINED</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           name area                            input  \\\n",
       "0         LOBBY  300         TEXT1: LOBBY; TEXT2: 300   \n",
       "1  STAFF OFFICE  220  TEXT1: STAFF OFFICE; TEXT2: 220   \n",
       "2     VESTIBULE  100     TEXT1: VESTIBULE; TEXT2: 100   \n",
       "\n",
       "                                    cat_prediction  \n",
       "0  FOOD AND BEVERAGE SERVICE: BAR, COCKTAIL LOUNGE  \n",
       "1  FOOD AND BEVERAGE SERVICE: BAR, COCKTAIL LOUNGE  \n",
       "2                                     USER-DEFINED  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Final outputs!\n",
    "label_dict\n",
    "reversed_dict = dict([(value, key) for key, value in label_dict.items()])\n",
    "\n",
    "pred_categories = []\n",
    "for prediction in preds:\n",
    "    category = reversed_dict[prediction]\n",
    "    pred_categories.append(category)\n",
    "pred_df['cat_prediction'] = pred_categories\n",
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfef1ae-dbad-4663-8588-ca34b80e05ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
